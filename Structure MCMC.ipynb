{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af19e85e",
   "metadata": {},
   "source": [
    "# Structure MCMC with DEO parallel tempering scheme (and dynamic tuning of temperatures)\n",
    "### $MC^3$, $REV$ and $MBR$ moves implemented\n",
    "In this notebook you can find the functions for sampling DAGs using a simple structure MCMC or using a structure MCMC with a parallel tempering scheme implemented (DEO, SEO and single swap schemes).\n",
    "\n",
    "Two structure priors implemented: uniform and sparse.\n",
    "\n",
    "\n",
    "A practical example of sampling DAGs using DEO Structure MCMC can be found at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ec1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import splines   \n",
    "from scipy.special import logsumexp\n",
    "from math import comb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf47a6",
   "metadata": {
    "hideCode": false,
    "id": "8dcf47a6"
   },
   "source": [
    "### Loading the score file for the data  from .jkl format (BDeu or BGe score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684d8f74",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "684d8f74",
    "outputId": "3573ac84-dc6e-45a2-d913-892aa3a8627a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def cache_f (path,max_parents,n_nodes):\n",
    "\n",
    "    with open(path,'r') as file:\n",
    "        filedata = file.readlines()\n",
    "\n",
    "    n_parents_set=[]\n",
    "    cache ={}\n",
    "    \n",
    "    t=1\n",
    "    vertices=[]\n",
    "    for i in range (n_nodes):\n",
    "        line = filedata[t]\n",
    "        vertices.append(int(re.findall(r'\\d+', line)[0]))\n",
    "        t+=int(re.findall(r'\\d+', line)[1])+1\n",
    "\n",
    "    t=1\n",
    "    for i in vertices :\n",
    "        line = filedata[t]\n",
    "        now_n_parents_set =int(re.findall(r'\\d+', line)[1])\n",
    "\n",
    "        n_parents_set.append(now_n_parents_set)\n",
    "        now_dict= {}\n",
    "\n",
    "        for j in range(now_n_parents_set):\n",
    "            now_parents=()\n",
    "            for k in range (len(re.findall(r'\\d+', filedata[t+j+1]))-3):\n",
    "\n",
    "                now_parents= now_parents + (int(re.findall(r'\\d+', filedata[t+j+1])[k+3]),)\n",
    "\n",
    "            now_parents=tuple(sorted(now_parents))\n",
    "\n",
    "            now_dict[now_parents]=float(filedata[t+j+1].split(' ')[0])\n",
    "        cache[i]=now_dict\n",
    "        t=t+now_n_parents_set+1\n",
    "    return cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a3f48",
   "metadata": {
    "hideCode": false,
    "id": "483a3f48"
   },
   "source": [
    "### Generic functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481a610d",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "481a610d",
    "outputId": "a7a1cd98-3494-4d2e-9af7-d444b081e8e9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_dag(adjacency_matrix):\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "\n",
    "    colors = np.zeros(num_nodes, dtype=int)\n",
    "\n",
    "    def dfs(node):\n",
    "        nonlocal colors\n",
    "\n",
    "        colors[node] = 1  \n",
    "\n",
    "        for neighbor in np.where(adjacency_matrix[node] == 1)[0]:\n",
    "            if colors[neighbor] == 1:\n",
    "                return False  \n",
    "            elif colors[neighbor] == 0:\n",
    "                if not dfs(neighbor):\n",
    "                    return False\n",
    "\n",
    "        colors[node] = 2 \n",
    "        return True\n",
    "\n",
    "    for node in range(num_nodes):\n",
    "        if colors[node] == 0:\n",
    "            if not dfs(node):\n",
    "                return False  \n",
    "\n",
    "    return True \n",
    "\n",
    "def generate_random_dag_adjacency_matrix(num_nodes,max_parents):\n",
    "    if num_nodes <= 0:\n",
    "        raise ValueError(\"Number of nodes must be greater than 0.\")\n",
    "\n",
    "    nodes = np.random.permutation(num_nodes)\n",
    "\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "\n",
    "    for i in range(num_nodes - 1):\n",
    "        num_edges = np.random.randint(1, num_nodes - i)\n",
    "\n",
    "        target_nodes = np.random.choice(nodes[i+1:], size=num_edges, replace=False)\n",
    "\n",
    "        adjacency_matrix[nodes[i], target_nodes] = 1\n",
    "\n",
    "    new_dag= np.zeros((num_nodes,num_nodes),dtype=np.int8)\n",
    "    for i in range (num_nodes):\n",
    "        a=list(np.where(adjacency_matrix[:,i]==1)[0])\n",
    "        b=random.randint(0,max_parents)\n",
    "        c=random.sample(sorted(a), min(len(a),b))\n",
    "        for j in c:\n",
    "            new_dag[j,i]=1\n",
    "    return new_dag\n",
    "\n",
    "\n",
    "def score(dag):\n",
    "    prior=1\n",
    "    loglik=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior= prior*(1/math.comb((n_variables-1),int(np.sum(dag[:,i]))))\n",
    "        loglik+= cache[i][tuple(np.where(dag[:,i]==1)[0])]\n",
    "    return loglik+ np.log(prior)\n",
    "\n",
    "\n",
    "\n",
    "def bisection_at_x (f,a,b,x,max_iter=100,tol=1e-6):\n",
    "    for i in range (max_iter):\n",
    "        c = (a + b) / 2\n",
    "        if ((f(c) == x) or ((b - a) / 2 < tol)):\n",
    "            return(c)\n",
    "        if (f(c)< x):\n",
    "            a = c\n",
    "        else:\n",
    "            b = c\n",
    "    return (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae1fe73",
   "metadata": {},
   "source": [
    "### Single $MC^3$ move (for structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c063b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mcmcmc (dag_now_p, loglik_now_p, prior_now_p, score_now_p,cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, max_parents,uniform\n",
    "\n",
    "    if beta==None:\n",
    "        beta=1\n",
    "    \n",
    "    dag0=np.copy(dag_now_p)\n",
    "    \n",
    "    condition=False\n",
    "    n_variables=len(dag_now_p[0])\n",
    "    while(condition==False):\n",
    "        u=random.randint(0, n_variables-1)\n",
    "        v=list(range(n_variables))\n",
    "        v.remove(u)\n",
    "        v=random.choice(v)\n",
    "        dag1=np.copy(dag_now_p)\n",
    "        if (dag_now_p[u,v]==1) :\n",
    "            dag1[u,v]=0\n",
    "        elif (dag_now_p[v,u]==1):\n",
    "            dag1[u,v]=1\n",
    "            dag1[v,u]=0\n",
    "            if (np.sum(dag_now_p[:,v])>=max_parents):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "        elif (dag_now_p[u,v]==0 and dag_now_p[v,u]==0):\n",
    "            dag1[u,v]=1\n",
    "            if np.sum(dag_now_p[:,v])>=max_parents:\n",
    "                dag1[u,v]=0\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "        condition=True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "    prior_0=np.copy(prior_now_p)\n",
    "    loglik_0=np.copy(loglik_now_p)\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/comb((n_variables-1),np.sum(dag1[:,i])))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "\n",
    "    prior_1=np.log(prior_1)\n",
    "\n",
    "    \n",
    "    alpha= min(beta*(loglik_1-loglik_0)+prior_1-prior_0,0)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "\n",
    "        dag_now=np.copy(dag1)\n",
    "        prior_now = np.copy(prior_1)\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now= np.copy(prior_now+loglik_now)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fb405",
   "metadata": {},
   "source": [
    "### Single $MC^3$ move (for PT Structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f06a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def pt_mcmcmc (dags_now_p, loglik_now_p, prior_now_p, beta,cache):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition=False\n",
    "    while(condition==False):\n",
    "        u=random.randint(0, n_variables-1)\n",
    "        v=list(range(n_variables))\n",
    "        v.remove(u)\n",
    "        v=random.choice(v)\n",
    "        dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "        if (dags_now_p[u,v,iterator]==1) :\n",
    "            dag1[u,v]=0\n",
    "\n",
    "        elif (dags_now_p[v,u,iterator]==1):\n",
    "            dag1[u,v]=1\n",
    "            dag1[v,u]=0\n",
    "            if  (np.sum(dags_now_p[:,v,iterator])>=max_parents):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "      \n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "        elif (dags_now_p[u,v,iterator]==0 and dags_now_p[v,u,iterator]==0):\n",
    "            dag1[u,v]=1\n",
    "            if  np.sum(dags_now_p[:,v,iterator])>=max_parents:\n",
    "                dag1[u,v]=0\n",
    "\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "        condition=True\n",
    "\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "    prior_0=np.copy(prior_now_p[iterator])\n",
    "    loglik_0=np.copy(loglik_now_p[iterator])\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag1[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "\n",
    "    prior_1=np.log(prior_1)\n",
    "\n",
    "    alpha= min(beta*(loglik_1-loglik_0)+prior_1-prior_0,0)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "\n",
    "        dags_now[:,:,iterator]=np.copy(dag1)\n",
    "        prior_now[iterator] = np.copy(prior_1)\n",
    "        loglik_now[iterator]= np.copy(loglik_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90bf5c1",
   "metadata": {},
   "source": [
    "### Single $REV$ move (for Structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9742c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "def rev (dag_now_p, loglik_now_p, prior_now_p, score_now_p, cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot,rand_steps,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dag_now_p)\n",
    "    dag0=np.copy(dag_now_p)\n",
    "\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        ind=np.where(dag0==1)\n",
    "        indexes=[]\n",
    " \n",
    "        for i in range (len(ind[0])):\n",
    "            indexes.append([ind[0][i],ind[1][i]])\n",
    "        \n",
    "        edge= random.sample(indexes,1)[0]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "  \n",
    "        pi_j=np.where(dag0[:,v])\n",
    "\n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        dag1[:,v]=np.zeros(n_variables)\n",
    "\n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "     \n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "           \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "            \n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "     \n",
    "                dd_u=list(set(dd_u))\n",
    "    \n",
    "        d_u=set(d_u)\n",
    " \n",
    "\n",
    "        d_v=np.where(dag1[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v))\n",
    " \n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "         \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "      \n",
    "                    d_v=np.append(d_v,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v=set(d_v)\n",
    "\n",
    "\n",
    "        pi_i_set=[item for item in cache[u] if v in item]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "            \n",
    "\n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i])\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "\n",
    "        \n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "\n",
    "        d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_v_plus=np.append(d_v_plus,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "        pi_j_cross_set=[item for item in cache[v]]\n",
    "        for i in d_v_plus:\n",
    "            pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "            \n",
    "\n",
    "        \n",
    "        z_j_cross=[]\n",
    "        for i in pi_j_cross_set:\n",
    "            if uniform==False:\n",
    "                z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_j_cross.append(cache[v][i])\n",
    "                \n",
    "        Z=np.copy(z_j_cross)\n",
    "        z_j_cross=logsumexp(z_j_cross)\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        for i in pi_j_tilde:\n",
    "            dag_tilde[i,v]=1\n",
    "            \n",
    "\n",
    "            \n",
    "        ''' backwards'''  \n",
    "            \n",
    "        pi_j_set_2=[item for item in cache[v] if u in item]\n",
    "        for i in d_v:\n",
    "            pi_j_set_2=[item for item in pi_j_set_2 if i not in item]   \n",
    "            \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_j_set_2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[v][i])\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        dag_tilde_cross=np.copy(dag1)\n",
    "        for i in pi_j:\n",
    "            dag_tilde_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        d_u_plus=np.where(dag_tilde_cross[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_tilde_cross[child,:]==1)[0]:\n",
    " \n",
    "                    d_u_plus=np.append(d_u_plus,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    " \n",
    "        d_u_plus=set(d_u_plus)\n",
    " \n",
    "        \n",
    "        \n",
    "        pi_i_cross_set=[item for item in cache[u]]\n",
    "        for i in d_u_plus:\n",
    "            pi_i_cross_set=[item for item in pi_i_cross_set if i not in item]\n",
    " \n",
    "        \n",
    "        z_i_cross=[]\n",
    "        for i in pi_i_cross_set:\n",
    "            if uniform==False:\n",
    "                z_i_cross.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_i_cross.append(cache[u][i])\n",
    "        z_i_cross=logsumexp(z_i_cross)\n",
    "        \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_tilde[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag_tilde[:,i]==1)[0])]\n",
    "\n",
    "    alpha=min(0,np.log(np.sum(dag0))-np.log(np.sum(dag_tilde))+z_star_i_dot_j+z_j_cross-z_star_j_dot_i-z_i_cross)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        dag_now=np.copy(dag_tilde)\n",
    "        prior_now = np.copy(np.log(prior_1))\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now=np.copy(loglik_now+prior_now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211de3f5",
   "metadata": {},
   "source": [
    "### Single $REV$ move (for PT structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1bf29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_rev (dags_now_p, loglik_now_p, prior_now_p, beta, cache):\n",
    "    global  dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        ind=np.where(dag0==1)\n",
    "        indexes=[]\n",
    "    \n",
    "        for i in range (len(ind[0])):\n",
    "            indexes.append([ind[0][i],ind[1][i]])\n",
    "        \n",
    "\n",
    "        edge= random.sample(indexes,1)[0]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "  \n",
    "\n",
    "        pi_j=np.where(dag0[:,v])\n",
    "\n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        dag1[:,v]=np.zeros(n_variables)\n",
    "  \n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "    \n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "      \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "                  \n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "     \n",
    "                dd_u=list(set(dd_u))\n",
    "      \n",
    "        d_u=set(d_u)\n",
    "  \n",
    "\n",
    "        d_v=np.where(dag1[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v))\n",
    "  \n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "       \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "           \n",
    "                    d_v=np.append(d_v,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "      \n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v=set(d_v)\n",
    "\n",
    "\n",
    "        pi_i_set=[item for item in cache[u] if v in item]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "    \n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta)\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    " \n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "\n",
    "        d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_v_plus=np.append(d_v_plus,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "        pi_j_cross_set=[item for item in cache[v]]\n",
    "        for i in d_v_plus:\n",
    "            pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "            \n",
    "\n",
    "        z_j_cross=[]\n",
    "        for i in pi_j_cross_set:\n",
    "            if uniform==False:\n",
    "                z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_j_cross.append(cache[v][i]*beta)\n",
    "        Z=np.copy(z_j_cross)\n",
    "        z_j_cross=logsumexp(z_j_cross)\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        for i in pi_j_tilde:\n",
    "            dag_tilde[i,v]=1\n",
    "            \n",
    "\n",
    "        ''' backwards'''  \n",
    "            \n",
    "        pi_j_set_2=[item for item in cache[v] if u in item]\n",
    "        for i in d_v:\n",
    "            pi_j_set_2=[item for item in pi_j_set_2 if i not in item]   \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_j_set_2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[v][i]*beta)\n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        dag_tilde_cross=np.copy(dag1)\n",
    "        for i in pi_j:\n",
    "            dag_tilde_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        d_u_plus=np.where(dag_tilde_cross[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_tilde_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_u_plus=np.append(d_u_plus,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u_plus=set(d_u_plus)\n",
    "\n",
    "        \n",
    "        \n",
    "        pi_i_cross_set=[item for item in cache[u]]\n",
    "        for i in d_u_plus:\n",
    "            pi_i_cross_set=[item for item in pi_i_cross_set if i not in item]\n",
    "\n",
    "        \n",
    "        z_i_cross=[]\n",
    "        for i in pi_i_cross_set:\n",
    "            if uniform==False:\n",
    "                z_i_cross.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_i_cross.append(cache[u][i]*beta)\n",
    "        z_i_cross=logsumexp(z_i_cross)\n",
    "        \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    alpha=min(0,np.log(np.sum(dag0))-np.log(np.sum(dag_tilde))+z_star_i_dot_j+z_j_cross-z_star_j_dot_i-z_i_cross)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        prior_1=1\n",
    "        loglik_1=0\n",
    "\n",
    "\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_tilde[:,i]))))\n",
    "            loglik_1+= cache[i][tuple(np.where(dag_tilde[:,i]==1)[0])]\n",
    "        \n",
    "        dags_now[:,:,iterator]=np.copy(dag_tilde)\n",
    "        prior_now[iterator]= np.copy(np.log(prior_1))\n",
    "        loglik_now[iterator]= np.copy(loglik_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ef235",
   "metadata": {},
   "source": [
    "### Single $MBR$ move (for structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d36c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbr (dag_now_p, loglik_now_p, prior_now_p, score_now_p, cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot,rand_steps,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dag_now_p)\n",
    "    dag0=np.copy(dag_now_p)\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        \n",
    "        u=random.randint(0,n_variables-1)\n",
    " \n",
    "        \n",
    "        pi_i=np.where(dag0[:,u]==1)[0]\n",
    "\n",
    "        \n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u=np.where(dag1[u,:]==1)[0]        \n",
    "        for i in c_u:\n",
    "            dag1[:,i]=np.zeros(n_variables)\n",
    "            dag1[u,i]=1\n",
    "        \n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "\n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u=set(d_u)\n",
    "\n",
    "        pi_i_set2=[item for item in cache[u]]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]\n",
    "\n",
    "        pi_i_set=pi_i_set2.copy()\n",
    "\n",
    "        for i in pi_i:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "\n",
    "        \n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i])\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "        \n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "        \n",
    "        ''' until here the new parents set of u is sampled'''\n",
    "        z_c=0\n",
    "        c_u=list(c_u)\n",
    "\n",
    "        random.shuffle(c_u)\n",
    "        c_u=tuple(c_u)\n",
    "\n",
    "        for v in c_u:\n",
    "\n",
    "            d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "\n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "                \n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i])\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c+=z_j_cross\n",
    "\n",
    "            \n",
    "            \n",
    "            log_probs = Z\n",
    "            num_categories = len(Z)\n",
    "            gumbels = np.random.gumbel(size=num_categories)\n",
    "            sample = np.argmax(log_probs + gumbels)\n",
    "            pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "            for i in pi_j_tilde:\n",
    "                dag_cross[i,v]=1\n",
    "\n",
    "        ''' backwards'''  \n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        dag_tilde[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u_b=np.where(dag_tilde[u,:]==1)[0]        \n",
    "        for i in c_u_b:\n",
    "            dag_tilde[:,i]=np.zeros(n_variables)\n",
    "            dag_tilde[u,i]=1\n",
    "\n",
    "        for i in pi_i_tilde:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]   \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_i_set2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[u][i])\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        for i in pi_i:\n",
    "            dag_tilde[i,u]=1\n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "        z_c_b=0\n",
    "        c_u_b=list(c_u_b)\n",
    "\n",
    "        random.shuffle(c_u_b)\n",
    "        c_u_b=tuple(c_u_b)\n",
    "        for v in c_u_b:\n",
    "            d_v_plus=np.where(dag_tilde[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "  \n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_tilde[child,:]==1)[0]:\n",
    "          \n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "        \n",
    "                    dd_v=list(set(dd_v))\n",
    "    \n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i])\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c_b+=np.copy(z_j_cross)\n",
    "\n",
    "            dag_tilde[:,v]=np.copy(dag0[:,v])\n",
    "    \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_cross[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag_cross[:,i]==1)[0])]\n",
    "\n",
    "    alpha=min(0,z_star_i_dot_j+z_c-z_star_j_dot_i-z_c_b)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        dag_now=np.copy(dag_cross)\n",
    "        prior_now = np.copy(np.log(prior_1))\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now=np.copy(loglik_now+prior_now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d5cbe",
   "metadata": {},
   "source": [
    "### Single $MBR$ move (for PT structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ca62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_mbr (dags_now_p, loglik_now_p, prior_now_p, beta, cache):\n",
    "    global  dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        \n",
    "        u=random.randint(0,n_variables-1)\n",
    "\n",
    "        \n",
    "        pi_i=np.where(dag0[:,u]==1)[0]\n",
    "\n",
    "        \n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u=np.where(dag1[u,:]==1)[0]        \n",
    "        for i in c_u:\n",
    "            dag1[:,i]=np.zeros(n_variables)\n",
    "            dag1[u,i]=1\n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "\n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u=set(d_u)\n",
    "\n",
    "        pi_i_set2=[item for item in cache[u]]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]\n",
    "\n",
    "        pi_i_set=pi_i_set2.copy()\n",
    "\n",
    "        for i in pi_i:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "\n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta)\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "        \n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "        \n",
    "        ''' until here the new parents set of u is sampled'''\n",
    "        z_c=0\n",
    "        c_u=list(c_u)\n",
    "\n",
    "        random.shuffle(c_u)\n",
    "        c_u=tuple(c_u)\n",
    "\n",
    "        for v in c_u:\n",
    "\n",
    "            d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "\n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "            \n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i]*beta)\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c+=z_j_cross\n",
    "\n",
    "            \n",
    "            log_probs = Z\n",
    "            num_categories = len(Z)\n",
    "            gumbels = np.random.gumbel(size=num_categories)\n",
    "            sample = np.argmax(log_probs + gumbels)\n",
    "            pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "            for i in pi_j_tilde:\n",
    "                dag_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        ''' backwards'''  \n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        dag_tilde[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u_b=np.where(dag_tilde[u,:]==1)[0]        \n",
    "        for i in c_u_b:\n",
    "            dag_tilde[:,i]=np.zeros(n_variables)\n",
    "            dag_tilde[u,i]=1\n",
    "        \n",
    "\n",
    "        for i in pi_i_tilde:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]   \n",
    "            \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_i_set2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[u][i]*beta)\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        for i in pi_i:\n",
    "            dag_tilde[i,u]=1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        z_c_b=0\n",
    "        c_u_b=list(c_u_b)\n",
    "\n",
    "        random.shuffle(c_u_b)\n",
    "        c_u_b=tuple(c_u_b)\n",
    "        for v in c_u_b:\n",
    "            d_v_plus=np.where(dag_tilde[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    " \n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_tilde[child,:]==1)[0]:\n",
    "   \n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i]*beta)\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c_b+=np.copy(z_j_cross)\n",
    "\n",
    "            dag_tilde[:,v]=np.copy(dag0[:,v])\n",
    "    \n",
    "\n",
    "        condition= True\n",
    "    \n",
    "\n",
    "    \n",
    "    alpha=min(0,z_star_i_dot_j+z_c-z_star_j_dot_i-z_c_b)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        prior_1=1\n",
    "        loglik_1=0\n",
    "\n",
    "\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_cross[:,i]))))\n",
    "            loglik_1+= cache[i][tuple(np.where(dag_cross[:,i]==1)[0])]\n",
    "        \n",
    "        dags_now[:,:,iterator]=np.copy(dag_cross)\n",
    "        prior_now[iterator]= np.copy(np.log(prior_1))\n",
    "        loglik_now[iterator]= np.copy(loglik_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8e087",
   "metadata": {},
   "source": [
    "### Structure MCMC without PT (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d83fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, prob_rev=.7, prob_mbr=.2,seed=None,uniform_p=False):\n",
    "    global score_now,n_variables, dag_now, loglik_now, prior_now, tot_swaps, max_parents,uniform\n",
    "\n",
    "    uniform=uniform_p\n",
    "    n_variables=int(n_variables_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    dag_now= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    dags =np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    scores=np.zeros(n_iter)\n",
    "\n",
    "    prior_now=1\n",
    "    loglik_now=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_now= prior_now*(1/comb((n_variables-1),np.sum(dag_now[:,i])))\n",
    "        loglik_now+= cache[i][tuple(np.where(dag_now[:,i]==1)[0])]\n",
    "    \n",
    "    prior_now=np.log(prior_now)\n",
    "    score_now=loglik_now+prior_now\n",
    "\n",
    "    dags[:,:,0]=dag_now\n",
    "    scores[0]=score_now\n",
    "    for i in range(n_iter-1):\n",
    "        r_num=random.random() \n",
    "        if r_num> prob_rev+prob_mbr:\n",
    "            mcmcmc(dag_now, loglik_now, prior_now, score_now, cache,1)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "\n",
    "        elif r_num<prob_rev:\n",
    "\n",
    "            rev(dag_now, loglik_now, prior_now, score_now, cache)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "        else:\n",
    "\n",
    "            mbr(dag_now, loglik_now, prior_now, score_now, cache)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "\n",
    "    return scores,dags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa380a6c",
   "metadata": {},
   "source": [
    "### DEO structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca0b6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deo_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            \n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "      \n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if (((j%2+k%2)==0) or ((j%2+k%2)==2)):\n",
    "\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "            if complete==True:\n",
    "                beta_array_train.append(list(betas))\n",
    "            \n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "        \n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "     \n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "\n",
    "                if (((j%2+k%2)==0) or ((j%2+k%2)==2)):\n",
    "\n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r,R,betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f8276",
   "metadata": {},
   "source": [
    "### Random single swap structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ac37c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "        \n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            \n",
    "            index=random.randint(0,n_chains-1)\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if j==index:\n",
    "\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "\n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "            if complete==True:\n",
    "                beta_array_train.append(list(betas))\n",
    "            \n",
    "\n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "\n",
    "        index=random.randint(0,n_chains-1)\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "                if j==index:\n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r,R,betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaab703",
   "metadata": {},
   "source": [
    "### SEO structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11dbc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seo_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            K=random.random()\n",
    "            if K<.5:\n",
    "                K=1\n",
    "            else:\n",
    "                K=2\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "                #print(alpha,j)\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if (((j%2+K%2)==0) or ((j%2+K%2)==2)):\n",
    "                        #print('swap',j)\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "        if complete==True:\n",
    "            beta_array_train.append(list(betas))\n",
    "            \n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        K=random.random()\n",
    "        if K<.5:\n",
    "            K=1\n",
    "        else:\n",
    "            K=2\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "        \n",
    "\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "\n",
    "                if (((j%2+K%2)==0) or ((j%2+K%2)==2)):\n",
    "          \n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r,R,betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5e196",
   "metadata": {},
   "source": [
    "### Diagnostic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef8f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restarts(chain):\n",
    "    rest=0\n",
    "    ground=np.zeros(chain[3])\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        ground[int(chain[2][0,i])]=1\n",
    "        if ground[int(chain[2][chain[3]-1,i])]==1:\n",
    "            ground[int(chain[2][chain[3]-1,i])]=0\n",
    "            rest+=1\n",
    "    return rest\n",
    "\n",
    "def plot_swaps (chain):\n",
    "    a=[]\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        a.append(int(np.where(chain[2][:,i]==2)[0]))\n",
    "    plt.plot(a)\n",
    "    plt.show()\n",
    "\n",
    "def score(dag,cache):\n",
    "    prior=1\n",
    "    loglik=0\n",
    "    n_variables=len(dag)\n",
    "    for i in range(n_variables):\n",
    "        prior= prior*(1/math.comb((n_variables-1),int(np.sum(dag[:,i]))))\n",
    "        loglik+= cache[i][tuple(np.where(dag[:,i]==1)[0])]\n",
    "    return loglik+ np.log(prior)\n",
    "\n",
    "def mixing_ratio(chain):\n",
    "    ratio_post=0\n",
    "    ratio=np.zeros(chain[3])\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        for j in range(chain[3]):\n",
    "            ratio[int(chain[2][j,i])]+=(chain[3]-1-j)/(chain[3])\n",
    "        ratio_post+= ratio[int(chain[2][chain[3]-1,i])]\n",
    "        ratio[int(chain[2][chain[3]-1,i])]=0\n",
    "    return ratio_post/len(chain[2][0,:])\n",
    "\n",
    "def dag_mean_post (x,start,end):\n",
    "    dim=len(x[:,0,0])\n",
    "    dag=np.zeros((dim,dim))\n",
    "    for i in range(start,end):\n",
    "        dag += x[:,:,i]\n",
    "    return dag/(end-start) \n",
    "\n",
    "def l1_loss(x,c,ref):\n",
    "    \n",
    "    dmp=[]\n",
    "    for i in x:\n",
    "        dmp.append(dag_mean_post(c[1],x[0],i))\n",
    "\n",
    "    u=[]\n",
    "    for i in dmp:\n",
    "        u.append(np.sum(np.abs(i-ref)))\n",
    "    return u\n",
    "\n",
    "def max_loss(x,c,ref):\n",
    "    \n",
    "    dmp=[]\n",
    "    for i in x:\n",
    "        dmp.append(dag_mean_post(c[1],x[0],i))\n",
    "\n",
    "    u=[]\n",
    "    for i in dmp:\n",
    "        u.append(np.max(np.abs(i-ref)))\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1c33a",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e4a8223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49490657 0.49695551 0.51388413 0.55111147 0.54781831 0.49128861\n",
      " 0.47496375 0.48469747 0.51997262 0.48830522 0.48723964 0.54125782] rejection ratio among chains\n",
      "[0.00000000e+00 5.78880310e-04 1.30367279e-03 2.70557404e-03\n",
      " 5.34915924e-03 9.15622711e-03 1.70660019e-02 4.36773300e-02\n",
      " 1.15519524e-01 2.24205971e-01 3.74270439e-01 6.09290123e-01\n",
      " 1.00000000e+00] betas\n"
     ]
    }
   ],
   "source": [
    "ASIA_cache=cache_f('data/asia-10000-3p.jkl',3,8)\n",
    "\n",
    "ASIA_structure_MCMC=deo_structure_mcmc (n_variables_p=8, max_parents_p=3, n_iter=50000, cache=ASIA_cache, training_iter=2000, n_chains_p=30, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f655d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of chains for parallel tempering:  13\n"
     ]
    }
   ],
   "source": [
    "ASIA_scores=ASIA_structure_MCMC[0]\n",
    "\n",
    "plt.plot(ASIA_scores[:100])\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('score')\n",
    "plt.title('Score traceplot ASIA during burn-in')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ASIA_scores[10000:])\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('score')\n",
    "plt.title('Score traceplot ASIA after burn-in')\n",
    "plt.show()\n",
    "\n",
    "print ('Optimal number of chains for parallel tempering: ', ASIA_structure_MCMC[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebb29f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAGs are represented as adjacency matrices, therefore the tensor that contains all the DAGs sampled has shape: \n",
      "(n_nodes, n_nodes, n_DAGs sampled) \n",
      "\n",
      "In our case the shape is: (8, 8, 52000) \n",
      " \n",
      "\n",
      "Posterior probability of the edges using matrix notation (each entry represents the posterior probability of the edge going from node i (row index) to node j (column index)) \n",
      "\n",
      "[[0.   0.65 0.67 0.   0.01 0.08 0.   0.  ]\n",
      " [0.35 0.   0.   0.02 0.04 0.97 0.02 0.  ]\n",
      " [0.33 0.   0.   0.01 0.03 0.03 0.   1.  ]\n",
      " [0.   0.02 0.01 0.   0.41 0.13 0.01 0.  ]\n",
      " [0.01 0.02 0.02 0.45 0.   0.96 0.02 0.  ]\n",
      " [0.   0.03 0.   0.02 0.04 0.   0.98 1.  ]\n",
      " [0.   0.   0.   0.   0.   0.01 0.   0.  ]\n",
      " [0.   0.   0.   0.01 0.   0.   0.01 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "ASIA_DAGs=ASIA_structure_MCMC[1]\n",
    "\n",
    "print('DAGs are represented as adjacency matrices, therefore the tensor that contains all the DAGs sampled has shape: \\n(n_nodes, n_nodes, n_DAGs sampled) \\n')\n",
    "\n",
    "print('In our case the shape is:', np.shape(ASIA_DAGs),'\\n \\n')\n",
    "\n",
    "\n",
    "print('Posterior probability of the edges using matrix notation (each entry represents the posterior probability of the edge going from node i (row index) to node j (column index)) \\n')\n",
    "\n",
    "print(np.around(dag_mean_post(x=ASIA_DAGs,start=10000,end=52000),2))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

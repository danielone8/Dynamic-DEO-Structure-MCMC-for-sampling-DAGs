{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af19e85e",
   "metadata": {},
   "source": [
    "# Structure MCMC with DEO parallel tempering scheme (and dynamic tuning of temperatures)\n",
    "### $MC^3$, $REV$ and $MBR$ moves implemented\n",
    "In this notebook you can find the functions for sampling DAGs using a simple structure MCMC or using a structure MCMC with a parallel tempering scheme implemented (DEO, SEO and single swap schemes).\n",
    "\n",
    "Two structure priors implemented: uniform and sparse.\n",
    "\n",
    "\n",
    "A practical example of sampling DAGs using DEO Structure MCMC can be found at the end of the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ec1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import splines   \n",
    "from scipy.special import logsumexp\n",
    "from math import comb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf47a6",
   "metadata": {
    "hideCode": false,
    "id": "8dcf47a6"
   },
   "source": [
    "### Loading the score file for the data  from .jkl format (BDeu score or BGe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684d8f74",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "684d8f74",
    "outputId": "3573ac84-dc6e-45a2-d913-892aa3a8627a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def cache_f (path,max_parents,n_nodes):\n",
    "\n",
    "    with open(path,'r') as file:\n",
    "        filedata = file.readlines()\n",
    "\n",
    "    n_parents_set=[]\n",
    "    cache ={}\n",
    "    \n",
    "    t=1\n",
    "    vertices=[]\n",
    "    for i in range (n_nodes):\n",
    "        line = filedata[t]\n",
    "        vertices.append(int(re.findall(r'\\d+', line)[0]))\n",
    "        t+=int(re.findall(r'\\d+', line)[1])+1\n",
    "\n",
    "    t=1\n",
    "    for i in vertices :\n",
    "        line = filedata[t]\n",
    "        now_n_parents_set =int(re.findall(r'\\d+', line)[1])\n",
    "\n",
    "        n_parents_set.append(now_n_parents_set)\n",
    "        now_dict= {}\n",
    "\n",
    "        for j in range(now_n_parents_set):\n",
    "            now_parents=()\n",
    "            for k in range (len(re.findall(r'\\d+', filedata[t+j+1]))-3):\n",
    "\n",
    "                now_parents= now_parents + (int(re.findall(r'\\d+', filedata[t+j+1])[k+3]),)\n",
    "\n",
    "            now_parents=tuple(sorted(now_parents))\n",
    "\n",
    "            now_dict[now_parents]=float(filedata[t+j+1].split(' ')[0])\n",
    "        cache[i]=now_dict\n",
    "        t=t+now_n_parents_set+1\n",
    "    return cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a3f48",
   "metadata": {
    "hideCode": false,
    "id": "483a3f48"
   },
   "source": [
    "### Generic functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481a610d",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "481a610d",
    "outputId": "a7a1cd98-3494-4d2e-9af7-d444b081e8e9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_dag(adjacency_matrix):\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "\n",
    "    colors = np.zeros(num_nodes, dtype=int)\n",
    "\n",
    "    def dfs(node):\n",
    "        nonlocal colors\n",
    "\n",
    "        colors[node] = 1  \n",
    "\n",
    "        for neighbor in np.where(adjacency_matrix[node] == 1)[0]:\n",
    "            if colors[neighbor] == 1:\n",
    "                return False  \n",
    "            elif colors[neighbor] == 0:\n",
    "                if not dfs(neighbor):\n",
    "                    return False\n",
    "\n",
    "        colors[node] = 2 \n",
    "        return True\n",
    "\n",
    "    for node in range(num_nodes):\n",
    "        if colors[node] == 0:\n",
    "            if not dfs(node):\n",
    "                return False  \n",
    "\n",
    "    return True \n",
    "\n",
    "def generate_random_dag_adjacency_matrix(num_nodes,max_parents):\n",
    "    if num_nodes <= 0:\n",
    "        raise ValueError(\"Number of nodes must be greater than 0.\")\n",
    "\n",
    "    nodes = np.random.permutation(num_nodes)\n",
    "\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "\n",
    "    for i in range(num_nodes - 1):\n",
    "        num_edges = np.random.randint(1, num_nodes - i)\n",
    "\n",
    "        target_nodes = np.random.choice(nodes[i+1:], size=num_edges, replace=False)\n",
    "\n",
    "        adjacency_matrix[nodes[i], target_nodes] = 1\n",
    "\n",
    "    new_dag= np.zeros((num_nodes,num_nodes),dtype=np.int8)\n",
    "    for i in range (num_nodes):\n",
    "        a=list(np.where(adjacency_matrix[:,i]==1)[0])\n",
    "        b=random.randint(0,max_parents)\n",
    "        c=random.sample(sorted(a), min(len(a),b))\n",
    "        for j in c:\n",
    "            new_dag[j,i]=1\n",
    "    return new_dag\n",
    "\n",
    "\n",
    "def score(dag):\n",
    "    prior=1\n",
    "    loglik=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior= prior*(1/math.comb((n_variables-1),int(np.sum(dag[:,i]))))\n",
    "        loglik+= cache[i][tuple(np.where(dag[:,i]==1)[0])]\n",
    "    return loglik+ np.log(prior)\n",
    "\n",
    "\n",
    "\n",
    "def bisection_at_x (f,a,b,x,max_iter=100,tol=1e-6):\n",
    "    for i in range (max_iter):\n",
    "        c = (a + b) / 2\n",
    "        if ((f(c) == x) or ((b - a) / 2 < tol)):\n",
    "            return(c)\n",
    "        if (f(c)< x):\n",
    "            a = c\n",
    "        else:\n",
    "            b = c\n",
    "    return (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae1fe73",
   "metadata": {},
   "source": [
    "### Single $MC^3$ move (for structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c063b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mcmcmc (dag_now_p, loglik_now_p, prior_now_p, score_now_p,cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, max_parents,uniform\n",
    "\n",
    "    if beta==None:\n",
    "        beta=1\n",
    "    \n",
    "    dag0=np.copy(dag_now_p)\n",
    "    \n",
    "    condition=False\n",
    "    n_variables=len(dag_now_p[0])\n",
    "    while(condition==False):\n",
    "        u=random.randint(0, n_variables-1)\n",
    "        v=list(range(n_variables))\n",
    "        v.remove(u)\n",
    "        v=random.choice(v)\n",
    "        dag1=np.copy(dag_now_p)\n",
    "        if (dag_now_p[u,v]==1) :\n",
    "            dag1[u,v]=0\n",
    "        elif (dag_now_p[v,u]==1):\n",
    "            dag1[u,v]=1\n",
    "            dag1[v,u]=0\n",
    "            if (np.sum(dag_now_p[:,v])>=max_parents):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "        elif (dag_now_p[u,v]==0 and dag_now_p[v,u]==0):\n",
    "            dag1[u,v]=1\n",
    "            if np.sum(dag_now_p[:,v])>=max_parents:\n",
    "                dag1[u,v]=0\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "        condition=True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "    prior_0=np.copy(prior_now_p)\n",
    "    loglik_0=np.copy(loglik_now_p)\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/comb((n_variables-1),np.sum(dag1[:,i])))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "\n",
    "    prior_1=np.log(prior_1)\n",
    "\n",
    "    \n",
    "    alpha= min(beta*(loglik_1-loglik_0)+prior_1-prior_0,0)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "\n",
    "        dag_now=np.copy(dag1)\n",
    "        prior_now = np.copy(prior_1)\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now= np.copy(prior_now+loglik_now)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fb405",
   "metadata": {},
   "source": [
    "### Single $MC^3$ move (for PT Structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f06a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def pt_mcmcmc (dags_now_p, loglik_now_p, prior_now_p, beta,cache):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition=False\n",
    "    while(condition==False):\n",
    "        u=random.randint(0, n_variables-1)\n",
    "        v=list(range(n_variables))\n",
    "        v.remove(u)\n",
    "        v=random.choice(v)\n",
    "        dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "        if (dags_now_p[u,v,iterator]==1) :\n",
    "            dag1[u,v]=0\n",
    "\n",
    "        elif (dags_now_p[v,u,iterator]==1):\n",
    "            dag1[u,v]=1\n",
    "            dag1[v,u]=0\n",
    "            if  (np.sum(dags_now_p[:,v,iterator])>=max_parents):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "      \n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "        elif (dags_now_p[u,v,iterator]==0 and dags_now_p[v,u,iterator]==0):\n",
    "            dag1[u,v]=1\n",
    "            if  np.sum(dags_now_p[:,v,iterator])>=max_parents:\n",
    "                dag1[u,v]=0\n",
    "\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "        condition=True\n",
    "\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "    prior_0=np.copy(prior_now_p[iterator])\n",
    "    loglik_0=np.copy(loglik_now_p[iterator])\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag1[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "\n",
    "    prior_1=np.log(prior_1)\n",
    "\n",
    "    alpha= min(beta*(loglik_1-loglik_0)+prior_1-prior_0,0)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "\n",
    "        dags_now[:,:,iterator]=np.copy(dag1)\n",
    "        prior_now[iterator] = np.copy(prior_1)\n",
    "        loglik_now[iterator]= np.copy(loglik_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90bf5c1",
   "metadata": {},
   "source": [
    "### Single $REV$ move (for Structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9742c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "def rev (dag_now_p, loglik_now_p, prior_now_p, score_now_p, cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot,rand_steps,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dag_now_p)\n",
    "    dag0=np.copy(dag_now_p)\n",
    "\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        ind=np.where(dag0==1)\n",
    "        indexes=[]\n",
    " \n",
    "        for i in range (len(ind[0])):\n",
    "            indexes.append([ind[0][i],ind[1][i]])\n",
    "        \n",
    "        edge= random.sample(indexes,1)[0]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "  \n",
    "        pi_j=np.where(dag0[:,v])\n",
    "\n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        dag1[:,v]=np.zeros(n_variables)\n",
    "\n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "     \n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "           \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "            \n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "     \n",
    "                dd_u=list(set(dd_u))\n",
    "    \n",
    "        d_u=set(d_u)\n",
    " \n",
    "\n",
    "        d_v=np.where(dag1[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v))\n",
    " \n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "         \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "      \n",
    "                    d_v=np.append(d_v,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v=set(d_v)\n",
    "\n",
    "\n",
    "        pi_i_set=[item for item in cache[u] if v in item]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "            \n",
    "\n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i])\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "\n",
    "        \n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "\n",
    "        d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_v_plus=np.append(d_v_plus,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "        pi_j_cross_set=[item for item in cache[v]]\n",
    "        for i in d_v_plus:\n",
    "            pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "            \n",
    "\n",
    "        \n",
    "        z_j_cross=[]\n",
    "        for i in pi_j_cross_set:\n",
    "            if uniform==False:\n",
    "                z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_j_cross.append(cache[v][i])\n",
    "                \n",
    "        Z=np.copy(z_j_cross)\n",
    "        z_j_cross=logsumexp(z_j_cross)\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        for i in pi_j_tilde:\n",
    "            dag_tilde[i,v]=1\n",
    "            \n",
    "\n",
    "            \n",
    "        ''' backwards'''  \n",
    "            \n",
    "        pi_j_set_2=[item for item in cache[v] if u in item]\n",
    "        for i in d_v:\n",
    "            pi_j_set_2=[item for item in pi_j_set_2 if i not in item]   \n",
    "            \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_j_set_2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[v][i])\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        dag_tilde_cross=np.copy(dag1)\n",
    "        for i in pi_j:\n",
    "            dag_tilde_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        d_u_plus=np.where(dag_tilde_cross[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_tilde_cross[child,:]==1)[0]:\n",
    " \n",
    "                    d_u_plus=np.append(d_u_plus,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    " \n",
    "        d_u_plus=set(d_u_plus)\n",
    " \n",
    "        \n",
    "        \n",
    "        pi_i_cross_set=[item for item in cache[u]]\n",
    "        for i in d_u_plus:\n",
    "            pi_i_cross_set=[item for item in pi_i_cross_set if i not in item]\n",
    " \n",
    "        \n",
    "        z_i_cross=[]\n",
    "        for i in pi_i_cross_set:\n",
    "            if uniform==False:\n",
    "                z_i_cross.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_i_cross.append(cache[u][i])\n",
    "        z_i_cross=logsumexp(z_i_cross)\n",
    "        \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_tilde[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag_tilde[:,i]==1)[0])]\n",
    "\n",
    "    alpha=min(0,np.log(np.sum(dag0))-np.log(np.sum(dag_tilde))+z_star_i_dot_j+z_j_cross-z_star_j_dot_i-z_i_cross)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        dag_now=np.copy(dag_tilde)\n",
    "        prior_now = np.copy(np.log(prior_1))\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now=np.copy(loglik_now+prior_now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211de3f5",
   "metadata": {},
   "source": [
    "### Single $REV$ move (for PT structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1bf29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_rev (dags_now_p, loglik_now_p, prior_now_p, beta, cache):\n",
    "    global  dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        ind=np.where(dag0==1)\n",
    "        indexes=[]\n",
    "    \n",
    "        for i in range (len(ind[0])):\n",
    "            indexes.append([ind[0][i],ind[1][i]])\n",
    "        \n",
    "\n",
    "        edge= random.sample(indexes,1)[0]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "  \n",
    "\n",
    "        pi_j=np.where(dag0[:,v])\n",
    "\n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        dag1[:,v]=np.zeros(n_variables)\n",
    "  \n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "    \n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "      \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "                  \n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "     \n",
    "                dd_u=list(set(dd_u))\n",
    "      \n",
    "        d_u=set(d_u)\n",
    "  \n",
    "\n",
    "        d_v=np.where(dag1[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v))\n",
    "  \n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "       \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "           \n",
    "                    d_v=np.append(d_v,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "      \n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v=set(d_v)\n",
    "\n",
    "\n",
    "        pi_i_set=[item for item in cache[u] if v in item]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "    \n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta)\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    " \n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "\n",
    "        d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_v_plus=np.append(d_v_plus,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "        pi_j_cross_set=[item for item in cache[v]]\n",
    "        for i in d_v_plus:\n",
    "            pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "            \n",
    "\n",
    "        z_j_cross=[]\n",
    "        for i in pi_j_cross_set:\n",
    "            if uniform==False:\n",
    "                z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_j_cross.append(cache[v][i]*beta)\n",
    "        Z=np.copy(z_j_cross)\n",
    "        z_j_cross=logsumexp(z_j_cross)\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        for i in pi_j_tilde:\n",
    "            dag_tilde[i,v]=1\n",
    "            \n",
    "\n",
    "        ''' backwards'''  \n",
    "            \n",
    "        pi_j_set_2=[item for item in cache[v] if u in item]\n",
    "        for i in d_v:\n",
    "            pi_j_set_2=[item for item in pi_j_set_2 if i not in item]   \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_j_set_2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[v][i]*beta)\n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        dag_tilde_cross=np.copy(dag1)\n",
    "        for i in pi_j:\n",
    "            dag_tilde_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        d_u_plus=np.where(dag_tilde_cross[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_tilde_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_u_plus=np.append(d_u_plus,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u_plus=set(d_u_plus)\n",
    "\n",
    "        \n",
    "        \n",
    "        pi_i_cross_set=[item for item in cache[u]]\n",
    "        for i in d_u_plus:\n",
    "            pi_i_cross_set=[item for item in pi_i_cross_set if i not in item]\n",
    "\n",
    "        \n",
    "        z_i_cross=[]\n",
    "        for i in pi_i_cross_set:\n",
    "            if uniform==False:\n",
    "                z_i_cross.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_i_cross.append(cache[u][i]*beta)\n",
    "        z_i_cross=logsumexp(z_i_cross)\n",
    "        \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    alpha=min(0,np.log(np.sum(dag0))-np.log(np.sum(dag_tilde))+z_star_i_dot_j+z_j_cross-z_star_j_dot_i-z_i_cross)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        prior_1=1\n",
    "        loglik_1=0\n",
    "\n",
    "\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_tilde[:,i]))))\n",
    "            loglik_1+= cache[i][tuple(np.where(dag_tilde[:,i]==1)[0])]\n",
    "        \n",
    "        dags_now[:,:,iterator]=np.copy(dag_tilde)\n",
    "        prior_now[iterator]= np.copy(np.log(prior_1))\n",
    "        loglik_now[iterator]= np.copy(loglik_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ef235",
   "metadata": {},
   "source": [
    "### Single $MBR$ move (for structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d36c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbr (dag_now_p, loglik_now_p, prior_now_p, score_now_p, cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot,rand_steps,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dag_now_p)\n",
    "    dag0=np.copy(dag_now_p)\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        \n",
    "        u=random.randint(0,n_variables-1)\n",
    " \n",
    "        \n",
    "        pi_i=np.where(dag0[:,u]==1)[0]\n",
    "\n",
    "        \n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u=np.where(dag1[u,:]==1)[0]        \n",
    "        for i in c_u:\n",
    "            dag1[:,i]=np.zeros(n_variables)\n",
    "            dag1[u,i]=1\n",
    "        \n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "\n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u=set(d_u)\n",
    "\n",
    "        pi_i_set2=[item for item in cache[u]]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]\n",
    "\n",
    "        pi_i_set=pi_i_set2.copy()\n",
    "\n",
    "        for i in pi_i:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "\n",
    "        \n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i])\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "        \n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "        \n",
    "        ''' until here the new parents set of u is sampled'''\n",
    "        z_c=0\n",
    "        c_u=list(c_u)\n",
    "\n",
    "        random.shuffle(c_u)\n",
    "        c_u=tuple(c_u)\n",
    "\n",
    "        for v in c_u:\n",
    "\n",
    "            d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "\n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "                \n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i])\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c+=z_j_cross\n",
    "\n",
    "            \n",
    "            \n",
    "            log_probs = Z\n",
    "            num_categories = len(Z)\n",
    "            gumbels = np.random.gumbel(size=num_categories)\n",
    "            sample = np.argmax(log_probs + gumbels)\n",
    "            pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "            for i in pi_j_tilde:\n",
    "                dag_cross[i,v]=1\n",
    "\n",
    "        ''' backwards'''  \n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        dag_tilde[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u_b=np.where(dag_tilde[u,:]==1)[0]        \n",
    "        for i in c_u_b:\n",
    "            dag_tilde[:,i]=np.zeros(n_variables)\n",
    "            dag_tilde[u,i]=1\n",
    "\n",
    "        for i in pi_i_tilde:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]   \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_i_set2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[u][i])\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        for i in pi_i:\n",
    "            dag_tilde[i,u]=1\n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "        z_c_b=0\n",
    "        c_u_b=list(c_u_b)\n",
    "\n",
    "        random.shuffle(c_u_b)\n",
    "        c_u_b=tuple(c_u_b)\n",
    "        for v in c_u_b:\n",
    "            d_v_plus=np.where(dag_tilde[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "  \n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_tilde[child,:]==1)[0]:\n",
    "          \n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "        \n",
    "                    dd_v=list(set(dd_v))\n",
    "    \n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i])\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c_b+=np.copy(z_j_cross)\n",
    "\n",
    "            dag_tilde[:,v]=np.copy(dag0[:,v])\n",
    "    \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_cross[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag_cross[:,i]==1)[0])]\n",
    "\n",
    "    alpha=min(0,z_star_i_dot_j+z_c-z_star_j_dot_i-z_c_b)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        dag_now=np.copy(dag_cross)\n",
    "        prior_now = np.copy(np.log(prior_1))\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now=np.copy(loglik_now+prior_now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d5cbe",
   "metadata": {},
   "source": [
    "### Single $MBR$ move (for PT structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ca62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_mbr (dags_now_p, loglik_now_p, prior_now_p, beta, cache):\n",
    "    global  dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        \n",
    "        u=random.randint(0,n_variables-1)\n",
    "\n",
    "        \n",
    "        pi_i=np.where(dag0[:,u]==1)[0]\n",
    "\n",
    "        \n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u=np.where(dag1[u,:]==1)[0]        \n",
    "        for i in c_u:\n",
    "            dag1[:,i]=np.zeros(n_variables)\n",
    "            dag1[u,i]=1\n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "\n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u=set(d_u)\n",
    "\n",
    "        pi_i_set2=[item for item in cache[u]]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]\n",
    "\n",
    "        pi_i_set=pi_i_set2.copy()\n",
    "\n",
    "        for i in pi_i:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "\n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta)\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "        \n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "        \n",
    "        ''' until here the new parents set of u is sampled'''\n",
    "        z_c=0\n",
    "        c_u=list(c_u)\n",
    "\n",
    "        random.shuffle(c_u)\n",
    "        c_u=tuple(c_u)\n",
    "\n",
    "        for v in c_u:\n",
    "\n",
    "            d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "\n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "            \n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i]*beta)\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c+=z_j_cross\n",
    "\n",
    "            \n",
    "            log_probs = Z\n",
    "            num_categories = len(Z)\n",
    "            gumbels = np.random.gumbel(size=num_categories)\n",
    "            sample = np.argmax(log_probs + gumbels)\n",
    "            pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "            for i in pi_j_tilde:\n",
    "                dag_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        ''' backwards'''  \n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        dag_tilde[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u_b=np.where(dag_tilde[u,:]==1)[0]        \n",
    "        for i in c_u_b:\n",
    "            dag_tilde[:,i]=np.zeros(n_variables)\n",
    "            dag_tilde[u,i]=1\n",
    "        \n",
    "\n",
    "        for i in pi_i_tilde:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]   \n",
    "            \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_i_set2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[u][i]*beta)\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        for i in pi_i:\n",
    "            dag_tilde[i,u]=1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        z_c_b=0\n",
    "        c_u_b=list(c_u_b)\n",
    "\n",
    "        random.shuffle(c_u_b)\n",
    "        c_u_b=tuple(c_u_b)\n",
    "        for v in c_u_b:\n",
    "            d_v_plus=np.where(dag_tilde[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    " \n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_tilde[child,:]==1)[0]:\n",
    "   \n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i]*beta)\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c_b+=np.copy(z_j_cross)\n",
    "\n",
    "            dag_tilde[:,v]=np.copy(dag0[:,v])\n",
    "    \n",
    "\n",
    "        condition= True\n",
    "    \n",
    "\n",
    "    \n",
    "    alpha=min(0,z_star_i_dot_j+z_c-z_star_j_dot_i-z_c_b)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        prior_1=1\n",
    "        loglik_1=0\n",
    "\n",
    "\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_cross[:,i]))))\n",
    "            loglik_1+= cache[i][tuple(np.where(dag_cross[:,i]==1)[0])]\n",
    "        \n",
    "        dags_now[:,:,iterator]=np.copy(dag_cross)\n",
    "        prior_now[iterator]= np.copy(np.log(prior_1))\n",
    "        loglik_now[iterator]= np.copy(loglik_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8e087",
   "metadata": {},
   "source": [
    "### Structure MCMC without PT (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d83fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, prob_rev=.7, prob_mbr=.2,seed=None,uniform_p=False):\n",
    "    global score_now,n_variables, dag_now, loglik_now, prior_now, tot_swaps, max_parents,uniform\n",
    "\n",
    "    uniform=uniform_p\n",
    "    n_variables=int(n_variables_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    dag_now= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    dags =np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    scores=np.zeros(n_iter)\n",
    "\n",
    "    prior_now=1\n",
    "    loglik_now=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_now= prior_now*(1/comb((n_variables-1),np.sum(dag_now[:,i])))\n",
    "        loglik_now+= cache[i][tuple(np.where(dag_now[:,i]==1)[0])]\n",
    "    \n",
    "    prior_now=np.log(prior_now)\n",
    "    score_now=loglik_now+prior_now\n",
    "\n",
    "    dags[:,:,0]=dag_now\n",
    "    scores[0]=score_now\n",
    "    for i in range(n_iter-1):\n",
    "        r_num=random.random() \n",
    "        if r_num> prob_rev+prob_mbr:\n",
    "            mcmcmc(dag_now, loglik_now, prior_now, score_now, cache,1)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "\n",
    "        elif r_num<prob_rev:\n",
    "\n",
    "            rev(dag_now, loglik_now, prior_now, score_now, cache)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "        else:\n",
    "\n",
    "            mbr(dag_now, loglik_now, prior_now, score_now, cache)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "\n",
    "    return scores,dags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa380a6c",
   "metadata": {},
   "source": [
    "### DEO structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca0b6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deo_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            \n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "      \n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if (((j%2+k%2)==0) or ((j%2+k%2)==2)):\n",
    "\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "            if complete==True:\n",
    "                beta_array_train.append(list(betas))\n",
    "            \n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "        \n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "     \n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "\n",
    "                if (((j%2+k%2)==0) or ((j%2+k%2)==2)):\n",
    "\n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r,R,betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f8276",
   "metadata": {},
   "source": [
    "### Random single swap structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ac37c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "        \n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            \n",
    "            index=random.randint(0,n_chains-1)\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if j==index:\n",
    "\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "\n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "            if complete==True:\n",
    "                beta_array_train.append(list(betas))\n",
    "            \n",
    "\n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "\n",
    "        index=random.randint(0,n_chains-1)\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "                if j==index:\n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r,R,betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaab703",
   "metadata": {},
   "source": [
    "### SEO structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11dbc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seo_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            K=random.random()\n",
    "            if K<.5:\n",
    "                K=1\n",
    "            else:\n",
    "                K=2\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "                #print(alpha,j)\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if (((j%2+K%2)==0) or ((j%2+K%2)==2)):\n",
    "                        #print('swap',j)\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "        if complete==True:\n",
    "            beta_array_train.append(list(betas))\n",
    "            \n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        K=random.random()\n",
    "        if K<.5:\n",
    "            K=1\n",
    "        else:\n",
    "            K=2\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "        \n",
    "\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "\n",
    "                if (((j%2+K%2)==0) or ((j%2+K%2)==2)):\n",
    "          \n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r,R,betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5e196",
   "metadata": {},
   "source": [
    "### Diagnostic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef8f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restarts(chain):\n",
    "    rest=0\n",
    "    ground=np.zeros(chain[3])\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        ground[int(chain[2][0,i])]=1\n",
    "        if ground[int(chain[2][chain[3]-1,i])]==1:\n",
    "            ground[int(chain[2][chain[3]-1,i])]=0\n",
    "            rest+=1\n",
    "    return rest\n",
    "\n",
    "def plot_swaps (chain):\n",
    "    a=[]\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        a.append(int(np.where(chain[2][:,i]==2)[0]))\n",
    "    plt.plot(a)\n",
    "    plt.show()\n",
    "\n",
    "def score(dag,cache):\n",
    "    prior=1\n",
    "    loglik=0\n",
    "    n_variables=len(dag)\n",
    "    for i in range(n_variables):\n",
    "        prior= prior*(1/math.comb((n_variables-1),int(np.sum(dag[:,i]))))\n",
    "        loglik+= cache[i][tuple(np.where(dag[:,i]==1)[0])]\n",
    "    return loglik+ np.log(prior)\n",
    "\n",
    "def mixing_ratio(chain):\n",
    "    ratio_post=0\n",
    "    ratio=np.zeros(chain[3])\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        for j in range(chain[3]):\n",
    "            ratio[int(chain[2][j,i])]+=(chain[3]-1-j)/(chain[3])\n",
    "        ratio_post+= ratio[int(chain[2][chain[3]-1,i])]\n",
    "        ratio[int(chain[2][chain[3]-1,i])]=0\n",
    "    return ratio_post/len(chain[2][0,:])\n",
    "\n",
    "def dag_mean_post (x,start,end):\n",
    "    dim=len(x[:,0,0])\n",
    "    dag=np.zeros((dim,dim))\n",
    "    for i in range(start,end):\n",
    "        dag += x[:,:,i]\n",
    "    return dag/(end-start) \n",
    "\n",
    "def l1_loss(x,c,ref):\n",
    "    \n",
    "    dmp=[]\n",
    "    for i in x:\n",
    "        dmp.append(dag_mean_post(c[1],x[0],i))\n",
    "\n",
    "    u=[]\n",
    "    for i in dmp:\n",
    "        u.append(np.sum(np.abs(i-ref)))\n",
    "    return u\n",
    "\n",
    "def max_loss(x,c,ref):\n",
    "    \n",
    "    dmp=[]\n",
    "    for i in x:\n",
    "        dmp.append(dag_mean_post(c[1],x[0],i))\n",
    "\n",
    "    u=[]\n",
    "    for i in dmp:\n",
    "        u.append(np.max(np.abs(i-ref)))\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1c33a",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e4a8223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53924585 0.52724642 0.48788243 0.48463854 0.48650809 0.54821263\n",
      " 0.53244527 0.5018718  0.50807195 0.48509332 0.47566966 0.4767625 ] rejection ratio among chains\n",
      "[0.00000000e+00 5.78880310e-04 1.27887726e-03 2.71892548e-03\n",
      " 5.54180145e-03 9.55867767e-03 1.75008774e-02 4.47683334e-02\n",
      " 1.14996910e-01 2.21961021e-01 3.76149178e-01 5.99381447e-01\n",
      " 1.00000000e+00] betas\n"
     ]
    }
   ],
   "source": [
    "ASIA_cache=cache_f('asia10k3.jkl',3,8)\n",
    "\n",
    "ASIA_structure_MCMC=deo_structure_mcmc (n_variables_p=8, max_parents_p=3, n_iter=50000, cache=ASIA_cache, training_iter=2000, n_chains_p=30, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f655d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of chains for parallel tempering:  13\n"
     ]
    }
   ],
   "source": [
    "ASIA_scores=ASIA_structure_MCMC[0]\n",
    "\n",
    "plt.plot(ASIA_scores[:100])\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('score')\n",
    "plt.title('Score traceplot ASIA during burn-in')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ASIA_scores[10000:])\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('score')\n",
    "plt.title('Score traceplot ASIA after burn-in')\n",
    "plt.show()\n",
    "\n",
    "print ('Optimal number of chains for parallel tempering: ', ASIA_structure_MCMC[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebb29f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAGs are represented as adjacency matrices, therefore the tensor that contains all the DAGs sampled has shape: \n",
      "(n_nodes, n_nodes, n_DAGs sampled) \n",
      "\n",
      "In our case the shape is: (8, 8, 52000) \n",
      " \n",
      "\n",
      "Posterior probability of the edges using matrix notation (each entry represents the posterior probability of the edge going from node i (row index) to node j (column index)) \n",
      "\n",
      "[[0.   0.66 0.66 0.   0.01 0.08 0.   0.  ]\n",
      " [0.34 0.   0.   0.02 0.03 0.98 0.02 0.  ]\n",
      " [0.34 0.   0.   0.   0.03 0.04 0.   1.  ]\n",
      " [0.   0.01 0.01 0.   0.41 0.14 0.01 0.  ]\n",
      " [0.01 0.02 0.02 0.47 0.   0.97 0.02 0.  ]\n",
      " [0.   0.02 0.   0.02 0.03 0.   0.98 1.  ]\n",
      " [0.   0.   0.   0.   0.   0.01 0.   0.  ]\n",
      " [0.   0.   0.   0.01 0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "ASIA_DAGs=ASIA_structure_MCMC[1]\n",
    "\n",
    "print('DAGs are represented as adjacency matrices, therefore the tensor that contains all the DAGs sampled has shape: \\n(n_nodes, n_nodes, n_DAGs sampled) \\n')\n",
    "\n",
    "print('In our case the shape is:', np.shape(ASIA_DAGs),'\\n \\n')\n",
    "\n",
    "\n",
    "print('Posterior probability of the edges using matrix notation (each entry represents the posterior probability of the edge going from node i (row index) to node j (column index)) \\n')\n",
    "\n",
    "print(np.around(dag_mean_post(x=ASIA_DAGs,start=10000,end=52000),2))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
